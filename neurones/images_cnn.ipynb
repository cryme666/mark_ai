{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc2a2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aedaf5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'CompleteImages'\n",
    "# Очікувані підпапки з цифрами від 0 до 9\n",
    "digit_labels = [str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee2c1177",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "img_size = (28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22873595",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in digit_labels:\n",
    "    folder_path = os.path.join(dataset_dir, label)\n",
    "    if not os.path.exists(folder_path):\n",
    "        continue  # Пропускаємо, якщо папка не існує\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                # Відкриваємо зображення, конвертуємо в чорно-біле та змінюємо розмір\n",
    "                img = Image.open(file_path).convert('L')\n",
    "                img = img.resize(img_size)\n",
    "                img_array = np.array(img) / 255.0\n",
    "                data.append(img_array)\n",
    "                labels.append(int(label))\n",
    "            except Exception as e:\n",
    "                print(f\"Помилка обробки {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da5221a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc5f4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(-1,img_size[0],img_size[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60c20c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "104527fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Valentyn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32,(3,3), activation='relu',input_shape = (28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(64,(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(10, activation = 'softmax')\n",
    "\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "462ac51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a64645a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5169/5169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 6ms/step - accuracy: 0.8488 - loss: 0.4590 - val_accuracy: 0.9722 - val_loss: 0.0893\n",
      "Epoch 2/10\n",
      "\u001b[1m5169/5169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - accuracy: 0.9738 - loss: 0.0800 - val_accuracy: 0.9768 - val_loss: 0.0673\n",
      "Epoch 3/10\n",
      "\u001b[1m5169/5169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6ms/step - accuracy: 0.9832 - loss: 0.0511 - val_accuracy: 0.9802 - val_loss: 0.0633\n",
      "Epoch 4/10\n",
      "\u001b[1m5169/5169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - accuracy: 0.9870 - loss: 0.0396 - val_accuracy: 0.9838 - val_loss: 0.0495\n",
      "Epoch 5/10\n",
      "\u001b[1m5169/5169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0315 - val_accuracy: 0.9875 - val_loss: 0.0394\n",
      "Epoch 6/10\n",
      "\u001b[1m5169/5169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0273 - val_accuracy: 0.9875 - val_loss: 0.0376\n",
      "Epoch 7/10\n",
      "\u001b[1m5169/5169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0234 - val_accuracy: 0.9885 - val_loss: 0.0366\n",
      "Epoch 8/10\n",
      "\u001b[1m5169/5169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0208 - val_accuracy: 0.9876 - val_loss: 0.0418\n",
      "Epoch 9/10\n",
      "\u001b[1m5169/5169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0181 - val_accuracy: 0.9902 - val_loss: 0.0327\n",
      "Epoch 10/10\n",
      "\u001b[1m5169/5169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0166 - val_accuracy: 0.9879 - val_loss: 0.0402\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs = 10,\n",
    "    batch_size = 32,\n",
    "    validation_data = (X_test,y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc5d5a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293/1293 - 3s - 2ms/step - accuracy: 0.9879 - loss: 0.0402\n",
      "Оцінка на тестових данних 98.7884%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,y_test,verbose = 2)\n",
    "print(f'Оцінка на тестових данних {test_acc * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67cc467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Розпізнана цифра: 9\n"
     ]
    }
   ],
   "source": [
    "# Шлях до тестового зображення\n",
    "test_img_path = 'CompleteImages/8/8_1_0.png'\n",
    "\n",
    "\n",
    "# Завантажуємо і обробляємо тестове зображення\n",
    "img = Image.open(test_img_path).convert('L')\n",
    "img = img.resize(img_size)\n",
    "img_array = img_array.reshape(1, img_size[0],img_size[1],1)\n",
    "\n",
    "# Прогнозуємо цифру\n",
    "predicted_digit = np.argmax(model.predict(img_array), axis = 1)[0]\n",
    "print(f\"Розпізнана цифра: {predicted_digit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d127e3c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
